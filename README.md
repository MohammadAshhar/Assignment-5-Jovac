Machine Learning Assignment 5: Naive Bayes, Decision Trees, and Ensemble Learning

This repository contains Jupyter notebooks and scripts for Tasks 1â€“9 covering Naive Bayes, Decision Trees, and Ensemble Methods, using text and numeric datasets. Follow the instructions below to reproduce the results.

ðŸ“‚ Directory Structure

â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ Task1_Theory_NaiveBayes.ipynb
â”‚   â”œâ”€â”€ Task2_SpamDetection_MultinomialNB.ipynb
â”‚   â”œâ”€â”€ Task3_GaussianNB_Iris.ipynb
â”‚   â”œâ”€â”€ Task4_Conceptual_DecisionTree.md
â”‚   â”œâ”€â”€ Task5_DecisionTree_Titanic.ipynb
â”‚   â”œâ”€â”€ Task6_ModelTuning_Titanic.ipynb
â”‚   â”œâ”€â”€ Task7_Conceptual_Ensemble.md
â”‚   â”œâ”€â”€ Task8_RF_vs_DT.ipynb
â”‚   â””â”€â”€ Task9_AdaBoost_Titanic.ipynb
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ sms.tsv              # SMS Spam Collection dataset
â”‚   â””â”€â”€ train_cleaned.csv    # Cleaned Titanic dataset
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt

 
 ðŸ“‹ Requirements

* Python 3.8+
* pandas
* scikit-learn
* matplotlib

Install dependencies via:
bash
pip install -r requirements.txt
 ðŸ“¥ Data Sources

1. SMS Spam Collection (TaskÂ 2)

   * Link: [https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection)
   * Preprocessed `.tsv` included as `data/sms.tsv`.

2. Iris Dataset (TaskÂ 3)

   Available in `sklearn.datasets`.

3. Titanic Dataset (TasksÂ 5â€“9)

   * Kaggle link: [https://www.kaggle.com/c/titanic/data](https://www.kaggle.com/c/titanic/data)
   * Raw `train.csv` must be downloaded to the working directory.
   * Cleaned version (after imputation & encoding) provided as `train_.csv`.


ðŸš€ Execution Steps

 Environment Setup

1. Clone the repository.
2. Create and activate a virtual environment (optional but recommended):

   python -m venv venv
   source venv/bin/activate  # macOS/Linux
   venv\Scripts\activate     # Windows
   
3. Install dependencies:

   pip install -r requirements.txt
 
 Running Notebooks

1. Launch Jupyter Notebook or JupyterLab in the project root:

   
   jupyter notebook
  
2. Open and execute each Task notebook in order: Task1 â†’ Task2 â†’ â€¦ â†’ Task9.

Scripts (Optional)

Each notebook can be exported as a standalone script (`.py`) and run via:


python notebooks/TaskX_Name.py

ðŸ”– Task Summaries

TaskÂ 1: Theory questions on Naive Bayes classifiers.
TaskÂ 2: SMS Spam detection with `MultinomialNB` and TF-IDF features.
TaskÂ 3: Classification on Iris dataset using `GaussianNB`, `DecisionTree`, `LogisticRegression`.
TaskÂ 4: Conceptual questions on Decision Trees (entropy, Gini, overfitting).
TaskÂ 5: Decision Tree on cleaned Titanic dataset (`train_cleaned.csv`), includes visualization.
TaskÂ 6: Hyperparameter tuning (`max_depth`, `min_samples_split`) with accuracy comparison plots.
TaskÂ 7: Conceptual questions on ensemble methods (Bagging vs Boosting, Random Forest variance, boosting weakness).
TaskÂ 8: Compare standalone Decision Tree vs `RandomForestClassifier`; plot feature importances.
TaskÂ 9: Train `AdaBoostClassifier` on Titanic, compare accuracy, F1, and training time against baselines.


ðŸ“„ License

This assignment code is for educational purposes. No license.
